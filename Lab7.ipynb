{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32ce9e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability that a student with an A grade is a hosteler: 0.692\n",
      "Probability of having the disease given a positive test result: 0.333\n"
     ]
    }
   ],
   "source": [
    "# Problem (a): Probability of being a hosteler given an A grade\n",
    "\n",
    "# Given probabilities\n",
    "P_H = 0.60  # Probability of being a hosteler\n",
    "P_D = 0.40  # Probability of being a day scholar\n",
    "P_A_given_H = 0.30  # Probability of A grade given hosteler\n",
    "P_A_given_D = 0.20  # Probability of A grade given day scholar\n",
    "\n",
    "# Total probability of A grade\n",
    "P_A = (P_A_given_H * P_H) + (P_A_given_D * P_D)\n",
    "\n",
    "# Probability of being a hosteler given an A grade\n",
    "P_H_given_A = (P_A_given_H * P_H) / P_A\n",
    "print(f\"Probability that a student with an A grade is a hosteler: {P_H_given_A:.3f}\")\n",
    "\n",
    "# Problem (b): Probability of having the disease given a positive test result\n",
    "\n",
    "# Given probabilities\n",
    "P_D = 0.01  # Prevalence of the disease\n",
    "P_D_not = 1 - P_D  # Probability of not having the disease\n",
    "P_T_given_D = 0.99  # Sensitivity (True Positive Rate)\n",
    "P_T_given_D_not = 0.02  # False Positive Rate\n",
    "\n",
    "# Total probability of testing positive\n",
    "P_T = (P_T_given_D * P_D) + (P_T_given_D_not * P_D_not)\n",
    "\n",
    "# Probability of having the disease given a positive test result\n",
    "P_D_given_T = (P_T_given_D * P_D) / P_T\n",
    "print(f\"Probability of having the disease given a positive test result: {P_D_given_T:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01ab4e45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.86\n",
      "Sample Prediction: Yes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "data = {\n",
    "    'age': ['<=30', '<=30', '31…40', '>40', '>40', '>40', '31…40', '<=30', '<=30', '>40', '<=30', '31…40', '31…40', '>40'],\n",
    "    'income': ['high', 'high', 'high', 'medium', 'low', 'low', 'low', 'medium', 'low', 'medium', 'medium', 'medium', 'high', 'medium'],\n",
    "    'student': ['no', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no'],\n",
    "    'credit_rating': ['fair', 'excellent', 'fair', 'fair', 'fair', 'excellent', 'excellent', 'fair', 'fair', 'fair', 'excellent', 'excellent', 'fair', 'excellent'],\n",
    "    'buys_computer': ['no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert categorical data into numerical data\n",
    "def encode_data(df):\n",
    "    return pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "df_encoded = encode_data(df)\n",
    "\n",
    "# Naïve Bayes classifier\n",
    "class NaiveBayesClassifier:\n",
    "    def __init__(self):\n",
    "        self.class_prob = {}\n",
    "        self.feature_probs = {}\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Compute prior probabilities\n",
    "        classes = y.unique()\n",
    "        self.class_prob = {c: np.mean(y == c) for c in classes}\n",
    "        \n",
    "        # Compute likelihoods\n",
    "        for feature in X.columns:\n",
    "            self.feature_probs[feature] = {}\n",
    "            for c in classes:\n",
    "                subset = X[y == c]\n",
    "                feature_probs = subset[feature].value_counts(normalize=True).to_dict()\n",
    "                self.feature_probs[feature][c] = feature_probs\n",
    "        \n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for _, row in X.iterrows():\n",
    "            posteriors = {}\n",
    "            for c in self.class_prob:\n",
    "                prior = self.class_prob[c]\n",
    "                likelihood = 1\n",
    "                for feature in X.columns:\n",
    "                    value = row[feature]\n",
    "                    if value in self.feature_probs[feature][c]:\n",
    "                        likelihood *= self.feature_probs[feature][c][value]\n",
    "                    else:\n",
    "                        likelihood *= 1e-6  # small value for unseen feature values\n",
    "                posteriors[c] = prior * likelihood\n",
    "            # Choose the class with the highest posterior probability\n",
    "            prediction = max(posteriors, key=posteriors.get)\n",
    "            predictions.append(prediction)\n",
    "        return np.array(predictions)\n",
    "\n",
    "# Prepare the data\n",
    "X = df_encoded.drop('buys_computer_yes', axis=1)\n",
    "y = df_encoded['buys_computer_yes']\n",
    "\n",
    "# Train the classifier\n",
    "model = NaiveBayesClassifier()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predict on the training set\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = np.mean(y_pred == y)\n",
    "print(f\"Training Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Prepare sample prediction\n",
    "# Ensure that sample columns match the training data columns\n",
    "sample = pd.DataFrame({\n",
    "    'age_31…40': [0],\n",
    "    'age_>40': [0],\n",
    "    'income_high': [1],\n",
    "    'income_low': [0],\n",
    "    'student_yes': [1],\n",
    "    'credit_rating_excellent': [0],\n",
    "    'credit_rating_fair': [1]\n",
    "})\n",
    "\n",
    "# Add any missing columns with default value 0\n",
    "for col in X.columns:\n",
    "    if col not in sample.columns:\n",
    "        sample[col] = 0\n",
    "\n",
    "# Ensure the order of columns matches\n",
    "sample = sample[X.columns]\n",
    "\n",
    "# Make prediction\n",
    "sample_prediction = model.predict(sample)\n",
    "print(f\"Sample Prediction: {'Yes' if sample_prediction[0] == 1 else 'No'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9693139b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.00\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "\n",
      "Sample Predictions:\n",
      "Sentence: 'A very close game'\n",
      "Prediction: Sports\n",
      "\n",
      "Sentence: 'A close election'\n",
      "Prediction: Sports\n",
      "\n",
      "Sentence: 'The game was thrilling'\n",
      "Prediction: Not sports\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import re\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# Load the dataset\n",
    "data = {\n",
    "    'Text': [\n",
    "        \"A great game\", \"The election was over\", \"Very clean match\", \"A clean but forgettable game\", \"It was a close election\"\n",
    "    ],\n",
    "    'Tag': [\n",
    "        \"Sports\", \"Not sports\", \"Sports\", \"Sports\", \"Not sports\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Preprocess the text data\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    return text\n",
    "\n",
    "df['Text'] = df['Text'].apply(preprocess_text)\n",
    "\n",
    "# Feature extraction: Bag-of-Words model\n",
    "def build_bow(df):\n",
    "    all_words = ' '.join(df['Text']).split()\n",
    "    vocab = set(all_words)\n",
    "    return vocab\n",
    "\n",
    "def text_to_features(text, vocab):\n",
    "    text_words = text.split()\n",
    "    features = {word: 0 for word in vocab}\n",
    "    for word in text_words:\n",
    "        if word in features:\n",
    "            features[word] += 1\n",
    "    return features\n",
    "\n",
    "# Create vocabulary\n",
    "vocab = build_bow(df)\n",
    "\n",
    "# Convert text to features\n",
    "def convert_to_features(df, vocab):\n",
    "    return df['Text'].apply(lambda x: text_to_features(x, vocab))\n",
    "\n",
    "X = convert_to_features(df, vocab)\n",
    "y = df['Tag']\n",
    "\n",
    "# Manual train-test split (small dataset)\n",
    "X_train = X[:3]\n",
    "y_train = y[:3]\n",
    "X_test = X[3:]\n",
    "y_test = y[3:]\n",
    "\n",
    "# Naïve Bayes classifier\n",
    "class NaiveBayesClassifier:\n",
    "    def __init__(self):\n",
    "        self.class_prob = {}\n",
    "        self.word_probs = defaultdict(lambda: defaultdict(lambda: 1e-6))  # Laplace smoothing\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        classes = y.unique()\n",
    "        total_docs = len(y)\n",
    "        class_counts = y.value_counts()\n",
    "        self.class_prob = {c: count / total_docs for c, count in class_counts.items()}\n",
    "\n",
    "        word_counts = {c: defaultdict(int) for c in classes}\n",
    "        class_doc_counts = class_counts.to_dict()\n",
    "\n",
    "        for idx, text_features in enumerate(X):\n",
    "            doc_class = y.iloc[idx]\n",
    "            for word, count in text_features.items():\n",
    "                word_counts[doc_class][word] += count\n",
    "\n",
    "        for c in classes:\n",
    "            total_words_in_class = sum(word_counts[c].values())\n",
    "            for word in vocab:\n",
    "                self.word_probs[word][c] = (word_counts[c][word] + 1) / (total_words_in_class + len(vocab))  # Laplace smoothing\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for text_features in X:\n",
    "            posteriors = {}\n",
    "            for c in self.class_prob:\n",
    "                prior = np.log(self.class_prob[c])\n",
    "                likelihood = 0\n",
    "                for word, count in text_features.items():\n",
    "                    if word in self.word_probs:\n",
    "                        likelihood += count * np.log(self.word_probs[word][c])\n",
    "                posteriors[c] = prior + likelihood\n",
    "            predictions.append(max(posteriors, key=posteriors.get))\n",
    "        return np.array(predictions)\n",
    "\n",
    "# Train the model\n",
    "model = NaiveBayesClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "precision = precision_score(y_test, y_pred, pos_label='Sports', average='binary', zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, pos_label='Sports', average='binary', zero_division=0)\n",
    "\n",
    "print(f\"Training Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "\n",
    "# Sample prediction\n",
    "sample_texts = [\n",
    "    \"A very close game\",\n",
    "    \"A close election\",\n",
    "    \"The game was thrilling\"\n",
    "]\n",
    "\n",
    "sample_features = [text_to_features(preprocess_text(text), vocab) for text in sample_texts]\n",
    "sample_predictions = model.predict(sample_features)\n",
    "\n",
    "# Print predictions in a readable format\n",
    "print(\"\\nSample Predictions:\")\n",
    "for text, prediction in zip(sample_texts, sample_predictions):\n",
    "    print(f\"Sentence: '{text}'\\nPrediction: {prediction}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a7a5f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
